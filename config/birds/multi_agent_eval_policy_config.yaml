defaults:
  - job_config
  - evaluator@evaluators.main: comparison
  - env/glider@evaluators.main.env.env: base_multiglider
  # - /env/glider/air_velocity_field@evaluators.main.env.env.air_velocity_field: ???
  - env/glider/aerodynamics@evaluators.main.env.env.aerodynamics: bird_glider_wing_loading_7
    
  - eval/initial_conditions@evaluators.main.env.env.params: common_initial_conditions
    
  - env/observation_logger@evaluators.main.observation_logger.env: singleglider_observation_logger
  - logger@logger: neptune_logger
  - override hydra/job_logging: custom_logging
  - _self_

experiment_name: multi_agent_eval
  
device: cpu

evaluation_policy:
  path: ???
  checkpoint: ???

evaluators:
  main:
    log_parent_key: eval_main
    episode_count: 1
    deterministic_comparison: true
    deterministic_eval: true
    compare_with_random_policy: false
    create_video: false
    observation_logger:
      log_buffer_size: 1000000
      additional_columns:
        thermal: multi_agent_eval
        agent_type: ai
        training: ${evaluation_policy.path}
    env:
      vectorized:
        count: 1
        parallel: false
      collector:
        exploration_noise: false
      env:
        params:
          max_sequence_length: ???
          max_closest_agent_count: ???

          agent_groups:
            teacher:
              terminate_if_finished: false
              order: 0
              spawner:
                pool_size: 10
                initial_time_offset_s_min_max: [0, 0]
                parallel_num_min_max: [0, 2]
                time_between_spawns_min_max_s: [30, 60]
                must_spawn_if_no_global_agent: false
              initial_conditions_params:
                tangent_position_parameters:
                  starting_distance_from_tangent_position_m_normal_mean: 50.0
                  starting_distance_from_tangent_position_m_normal_sigma: 0.0
                  starting_distance_from_tangent_position_m_normal_sigma_k: 1.
                  tangent_distance_from_core_m_normal_mean: 10.0
                  tangent_distance_from_core_m_normal_sigma: 0.
                  tangent_distance_from_core_m_normal_sigma_k: 1.
                altitude_earth_m_mean: 400.0
                altitude_earth_m_sigma: 50.0
                altitude_earth_m_sigma_k: 2.5            
            student:
              terminate_if_finished: true
              order: 1
              spawner:
                pool_size: 1
                initial_time_offset_s_min_max: [30, 90]
                #initial_time_offset_s: 0.
                parallel_num_min_max: [1, 1]
                time_between_spawns_min_max_s: [1, 1]
                # must_spawn_if_no_global_agent: true
                must_spawn_if_no_global_agent: true
              initial_conditions_params:
                tangent_position_parameters:
                  starting_distance_from_tangent_position_m_normal_mean: 350.0
                  starting_distance_from_tangent_position_m_normal_sigma: 0.0
                  starting_distance_from_tangent_position_m_normal_sigma_k: 1.
                  tangent_distance_from_core_m_normal_mean: 250.0
                  tangent_distance_from_core_m_normal_sigma: 0.
                  tangent_distance_from_core_m_normal_sigma_k: 1.
                altitude_earth_m_mean: 400.
                altitude_earth_m_sigma: 50.0
                altitude_earth_m_sigma_k: 2.5
          simulation_box_params:
            box_size: [7000,7000,2000]
          reward_params:
            success_reward: 0.
            fail_reward: 0.
            negative_reward_enabled: true
            vertical_velocity_reward_enabled: true
            new_maximum_altitude_reward_enabled: true
          cutoff_params:
            maximum_distance_from_core_m: 700.0
            success_altitude_m: 1500.0
            fail_altitude_m: 10.0
            maximum_time_without_lift_s: 600.0
            maximum_duration_s: 3000.0
          time_params:
            dt_s: 0.4
            decision_dt_s: 0.8
          discrete_continuous_mapping:
            discrete_count: 13
            low_deg: -45.0
            high_deg: 45.0
          glider_agent_params:
            roll_control_dynamics_params:
              system:
                omega_natural_frequency: 0.2
                zeta_damping_ratio: 0.5
                k_process_gain: 1.
              control:
                proportional_gain: 15.
                integral_gain: 0.66
                derivative_gain: 40.
            # air_velocity_post_process:
            #   # filter_kernel:
            #   #   kernel_size: 10
            #   #   alpha: 0.25
            #   velocity_noise:
            #     x:
            #       mean: 0.0
            #       sigma: 0.01
            #     y:
            #       mean: 0.0
            #       sigma: 0.01
            #     z:
            #       mean: 0.0
            #       sigma: 0.01

hydra:
  job_logging:
    loggers:
      VectorizedObservationLogger:
        level: DEBUG
      VectorizedVideoRecorder:
        level: DEBUG
      TianshouEvaluationJob:
        level: DEBUG
      TianshouEvaluator:
        level: DEBUG
      TianshouComparisonEvaluator:
        level: DEBUG
      thermal.realistic.make_stacked_decomposed_realistic_air_velocity_field:
        level: DEBUG
      MultirunHydraStatisticsConcatCallback:
        level: DEBUG
      GliderInitialConditionsCalculator:
        level: DEBUG
      GliderInitialTangentPosition:
        level: DEBUG
      TianshouVectorizedCollectorFactory:
        level: DEBUG
      find_suitable_torch_device:
        level: DEBUG
